{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53636de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/29 12:44:38 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/05/29 12:44:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "25/05/29 12:44:38 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"test_pyspark\") \\\n",
    "    .config(\"spark.driver.memory\", \"100g\") \\\n",
    "    .config(\"spark.executor.memory\", \"100g\") \\\n",
    "    .config(\"spark.sql.orc.enableVectorizedReader\", \"false\") \\\n",
    "    .config(\"spark.sql.parquet.columnarReaderBatchSize\", \"256\") \\\n",
    "    .config(\"spark.sql.orc.columnarReaderBatchSize\", \"256\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5edeb69",
   "metadata": {},
   "source": [
    "# Spellcheck Text Renderings (OCRs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9603e894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/frequency_dictionary_en_82_765.txt already exists.\n",
      "Added frequency_dictionary_en_82_765.txt to Spark context.\n",
      "SymSpell dictionary loaded successfully for testing on driver.\n",
      "SymSpell dictionary loaded successfully for testing on driver.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.sql import functions as F\n",
    "import re\n",
    "import pandas as pd # For Pandas UDF type hint\n",
    "\n",
    "# Define paths for dictionary files\n",
    "data_dir = \"../data\"\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "dictionary_path = os.path.join(data_dir, \"tmp\", \"frequency_dictionary_en_82_765.txt\")\n",
    "\n",
    "# URL for the dictionary\n",
    "dict_url = \"https://raw.githubusercontent.com/wolfgarbe/SymSpell/refs/heads/master/SymSpell/frequency_dictionary_en_82_765.txt\"\n",
    "\n",
    "def download_file(url, dest_path):\n",
    "    if not os.path.exists(dest_path):\n",
    "        print(f\"Downloading {url} to {dest_path}...\")\n",
    "        try:\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status() # Raise an exception for HTTP errors\n",
    "            with open(dest_path, \"wb\") as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(\"Download complete.\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading {url}: {e}\")\n",
    "            # Optionally, re-raise or handle as critical error\n",
    "            raise\n",
    "    else:\n",
    "        print(f\"{dest_path} already exists.\")\n",
    "\n",
    "try:\n",
    "    download_file(dict_url, dictionary_path)\n",
    "\n",
    "    # Add dictionary file to Spark context so it's available on workers\n",
    "    spark.sparkContext.addFile(dictionary_path)\n",
    "    print(f\"Added {os.path.basename(dictionary_path)} to Spark context.\")\n",
    "\n",
    "    # Test dictionary loading on the driver side (optional)\n",
    "    sym_spell_test = SymSpell(max_dictionary_edit_distance=2, prefix_length=7)\n",
    "    if sym_spell_test.load_dictionary(dictionary_path, term_index=0, count_index=1):\n",
    "        print(\"SymSpell dictionary loaded successfully for testing on driver.\")\n",
    "    else:\n",
    "        print(\"Failed to load SymSpell dictionary for testing on driver.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during dictionary setup: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cfca517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas UDF 'calculate_misspelled_ratio' defined.\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import pandas_udf\n",
    "from pyspark.sql.types import FloatType\n",
    "from symspellpy import SymSpell, Verbosity # Ensure it's available for UDF context\n",
    "import re\n",
    "import os # For basename in UDF\n",
    "import pandas as pd # For type hint pd.Series\n",
    "\n",
    "# Get the basename of the dictionary file that was added to SparkFiles\n",
    "# This ensures the UDF uses the correct path on worker nodes\n",
    "# Note: dictionary_path is from the previous cell's scope. If running cells separately, ensure it's defined.\n",
    "# For robustness in notebook execution, re-define or pass as argument if necessary.\n",
    "# However, spark.sparkContext.addFile makes it findable by basename.\n",
    "dictionary_filename = os.path.basename(dictionary_path) \n",
    "\n",
    "@pandas_udf(FloatType()) \n",
    "def calculate_misspelled_ratio(texts: pd.Series) -> pd.Series:\n",
    "    # Initialize SymSpell inside the UDF\n",
    "    # max_dictionary_edit_distance must be >= max_edit_distance used in lookup\n",
    "    sym_spell = SymSpell(max_dictionary_edit_distance=1, prefix_length=7)\n",
    "    \n",
    "    # Import SparkFiles inside UDF to get path on worker\n",
    "    from pyspark import SparkFiles # Lazy import for worker context\n",
    "    local_dictionary_path = SparkFiles.get(dictionary_filename)\n",
    "    \n",
    "    if not os.path.exists(local_dictionary_path) or \\\n",
    "       not sym_spell.load_dictionary(local_dictionary_path, term_index=0, count_index=1):\n",
    "        # If dictionary load fails on worker, return error code or NaN\n",
    "        return pd.Series([float('nan')] * len(texts))\n",
    "\n",
    "    results = []\n",
    "    for text in texts:\n",
    "        if pd.isna(text) or not isinstance(text, str) or not text.strip():\n",
    "            results.append(0.0) # Treat empty/invalid text as having no misspellings\n",
    "            continue\n",
    "\n",
    "        # Preprocessing: lowercase, keep only English letters and spaces, then split\n",
    "        clean_text = re.sub(r'[^a-z\\s]', '', str(text).lower())\n",
    "        words = [word for word in clean_text.split() if word] \n",
    "\n",
    "        if not words:\n",
    "            results.append(0.0) # No words to check\n",
    "            continue\n",
    "\n",
    "        misspelled_count = 0\n",
    "        for word in words:\n",
    "            # max_edit_distance=1: try to find the word with at most 1 edit\n",
    "            # Verbosity.TOP: return only the top suggestion\n",
    "            # include_unknown=True: if word not found, it's returned itself with count 0\n",
    "            suggestions = sym_spell.lookup(word, Verbosity.TOP, max_edit_distance=1, include_unknown=True)\n",
    "            \n",
    "            # A word is misspelled if:\n",
    "            # 1. No suggestions (should not happen with include_unknown=True)\n",
    "            # 2. The top suggestion's term is different from the original word.\n",
    "            # 3. The top suggestion's term is the same, but its count is 0 (meaning it's unknown to the dictionary).\n",
    "            if not suggestions: # Should ideally not be hit with include_unknown=True\n",
    "                misspelled_count +=1\n",
    "            else:\n",
    "                top_suggestion = suggestions[0]\n",
    "                if top_suggestion.term != word or top_suggestion.count == 0:\n",
    "                    misspelled_count += 1\n",
    "        \n",
    "        ratio = misspelled_count / len(words) if len(words) > 0 else 0.0\n",
    "        results.append(ratio)\n",
    "        \n",
    "    return pd.Series(results)\n",
    "\n",
    "print(\"Pandas UDF 'calculate_misspelled_ratio' defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37536669",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:======================================================>(259 + 4) / 263]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing approximately 96 records for spellcheck analysis.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:======================================================>(259 + 4) / 263]\r"
     ]
    }
   ],
   "source": [
    "from wc_simd.utility import spark_path\n",
    "\n",
    "text_df = spark.read.parquet(spark_path(\n",
    "    \"../data/plain_text_rendering.parquet\")).sample(False, 0.0005, seed=42)\n",
    "works_df = spark.table(\"works\")\n",
    "\n",
    "works_in_text_df = (\n",
    "    works_df\n",
    "    .join(\n",
    "        text_df,\n",
    "        works_df.id == text_df.id,\n",
    "        \"inner\"\n",
    "    )\n",
    "    .select(works_df[\"id\"], works_df[\"languages\"], text_df[\"text\"])\n",
    ")\n",
    "\n",
    "# Extract the first language from the languages array\n",
    "works_in_text_df_first_lang = works_in_text_df.withColumn(\n",
    "    \"first_language\", F.col(\"languages\")[0][\"id\"])\n",
    "\n",
    "# For demonstration, take a small sample. Adjust sample size as needed.\n",
    "# Spellchecking can be computationally intensive.\n",
    "# Using a fraction of 0.0005 (0.05%) for initial testing.\n",
    "# Increase fraction for more comprehensive analysis if performance allows.\n",
    "sampled_text_df = works_in_text_df_first_lang.where(F.col(\"first_language\") == \"eng\")\n",
    "\n",
    "print(\n",
    "    f\"Processing approximately {\n",
    "        sampled_text_df.count()} records for spellcheck analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42870d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:============================================>        (167 + 33) / 200]\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sampled_text_df.write.saveAsTable(\"sampled_text_df\", mode=\"overwrite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d4c1e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_text_df = spark.table(\"sampled_text_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9f47f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample results with misspelled_ratio:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------------------+----------------+\n",
      "|      id|                                              text|misspelled_ratio|\n",
      "+--------+--------------------------------------------------+----------------+\n",
      "|qh3zjc7x|6 ANNUAL REPORTS of the medical officer of heal...|       0.1433239|\n",
      "|jb5napff|EX BIBLIOTHECA CAR. I. TAB ORI S MINOR SURGERY ...|      0.16810748|\n",
      "|r5yjxxbr|DEPARTMENT OF OBSTETRICS & GYNECOLOGY YALE UNIV...|      0.16791707|\n",
      "|ab8ud2qv|HOMCEOPATHY UNVEJLED OR, OBSERVATIONS ON HAHNEM...|      0.11810287|\n",
      "|dn2qn93b|THE SIXTY-SEVENTH REPORT OF THE LONDON FEVER HO...|      0.29506704|\n",
      "|am6mzvqk|Egkm Urban Sanitary District. REPORT TO THE URB...|      0.17860554|\n",
      "|tc2z7q2e|) ' I I r r THE SCIENCE AND ART OF MIDWIFEEY. B...|      0.21040253|\n",
      "|sgu2zcbh|SUTTON-IN-ASHFIELD URBAN DISTRICT COUNCIL Chair...|      0.17836677|\n",
      "|mhx6vvxq|, > . M'2 ' ; /: . . - V . Â«. * .y\"S . a w : '...|      0.10701774|\n",
      "|zzxfabmk|BOROUGH OF REIGATE. ANNUAL REPORT OF THE Medica...|     0.120414965|\n",
      "|mw3nawbp|The University Library Leeds â ââ Medical...|       0.1477902|\n",
      "|jkutanym|iiiiiiiiiiiiSiliiiiililii!:: ;i!i!iii!iHiiie!!i...|      0.13280644|\n",
      "|vy6pp7xp|CLAUDIUS ASH & SONS Â©enfaf ^fubenfe* &t0?Â£irg...|      0.21139215|\n",
      "|das3hf3z|â â â. â â â â â â¢> â â â...|      0.50341946|\n",
      "|t2xa4j7u|COUNTY OF THE ISLE OF WIGHT REPORT OF THE Count...|      0.13897783|\n",
      "|fj3u74qn|J>FwR ijlj 22900409976 Digitized by the Interne...|      0.15492886|\n",
      "|qbazcuh3|* Pe ; â : Ra sae F Â« . â Â» â a Co ! , ...|       0.3040904|\n",
      "|qv29f3rh|^Â¥\"0 rte Editors of the National I nielli t.'-...|      0.15884426|\n",
      "|zapmn8mp|/ (6J TREATMENT OF DIABETES BY MEANS OF WATER C...|       0.1842576|\n",
      "|vf3366s6|                N DOROTHY S.AINSWORTH _ XQ MARI...|      0.14214508|\n",
      "+--------+--------------------------------------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Total records to process: 96\n",
      "Total records to process: 96\n"
     ]
    }
   ],
   "source": [
    "# Apply the UDF\n",
    "# Ensure to select relevant columns and dropna for the column used in UDF if it can be null\n",
    "# The UDF itself handles None/NaN for text, so direct application is fine.\n",
    "df_with_spellcheck = sampled_text_df.withColumn(\"misspelled_ratio\", calculate_misspelled_ratio(F.col(\"text\")))\n",
    "\n",
    "# Show some results, including cases that might be problematic\n",
    "print(\"Sample results with misspelled_ratio:\")\n",
    "df_with_spellcheck.select(\"id\", \"text\", \"misspelled_ratio\").show(20, truncate=50)\n",
    "\n",
    "# Cache the result if you plan to reuse it for multiple analyses\n",
    "# df_with_spellcheck.cache()\n",
    "\n",
    "# Trigger action to compute and cache\n",
    "print(f\"Total records to process: {df_with_spellcheck.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668a037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd # Ensure pandas is imported for .toPandas()\n",
    "\n",
    "# Ensure df_with_spellcheck is computed and available\n",
    "if 'df_with_spellcheck' in locals() and df_with_spellcheck is not None:\n",
    "    # Collect the misspelled_ratio for analysis\n",
    "    # Filter out any potential NaN values if UDF returned them for errors\n",
    "    misspelled_ratios_pd = df_with_spellcheck.select(\"misspelled_ratio\").dropna().toPandas()\n",
    "\n",
    "    if not misspelled_ratios_pd.empty:\n",
    "        plt.figure(figsize=(12, 7))\n",
    "        sns.histplot(misspelled_ratios_pd[\"misspelled_ratio\"], bins=30, kde=True) # Added KDE for smooth distribution\n",
    "        plt.title(\"Histogram of Misspelled Word Ratio in Sampled OCR Texts\")\n",
    "        plt.xlabel(\"Misspelled Word Ratio (0 = perfect, 1 = all misspelled)\")\n",
    "        plt.ylabel(\"Number of Documents\")\n",
    "        plt.grid(axis='y', alpha=0.75)\n",
    "        plt.show()\n",
    "\n",
    "        # Print descriptive statistics\n",
    "        print(\"\\nDescriptive statistics for misspelled_ratio:\")\n",
    "        print(misspelled_ratios_pd[\"misspelled_ratio\"].describe(percentiles=[.01, .05, .25, .5, .75, .95, .99]))\n",
    "    else:\n",
    "        print(\"No valid misspelled_ratio data to plot or describe. Check UDF execution, data sampling, or filtering.\")\n",
    "\n",
    "    # Unpersist the cached DataFrame if no longer needed\n",
    "    # df_with_spellcheck.unpersist()\n",
    "    # print(\"Unpersisted df_with_spellcheck.\")\n",
    "else:\n",
    "    print(\"df_with_spellcheck is not defined or is None. Please run the previous cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e698f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_spellcheck_pd = df_with_spellcheck.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc9247",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_spellcheck_pd.to_csv(\n",
    "    \"../data/tmp/text_with_spellcheck_eng_sample.csv\",\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af24bc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_with_spellcheck_pd = pd.read_csv(\n",
    "    \"../data/tmp/text_with_spellcheck_eng_sample.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23f3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_spellcheck_pd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
