{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfcb4a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pymongo\n",
    "from pymongo.database import Database\n",
    "from pymongo.operations import SearchIndexModel\n",
    "\n",
    "\n",
    "MONGODB_CONNECTION_STRING = \"mongodb://user:pass@localhost:27017/?directConnection=true\"\n",
    "MONGODB_DB_NAME = \"imagetalk\"\n",
    "DIMENSIONS = 1536  # <-- set this to match your embedding size\n",
    "\n",
    "\n",
    "# Connect to CosmosDB (MongoDB API)\n",
    "client = pymongo.MongoClient(MONGODB_CONNECTION_STRING)\n",
    "# Replace with your database name\n",
    "db: Database = client[MONGODB_DB_NAME]\n",
    "\n",
    "image_collection = db[\"images\"]\n",
    "processed_collection = db[\"processed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e42441f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'embedding_vector_index'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize collections\n",
    "\n",
    "# UNCOMMENT the following lines if you want to start fresh\n",
    "\n",
    "\n",
    "# image_collection.create_index(\"image_id\", unique=True)\n",
    "# processed_collection.create_index(\"file\", unique=True)\n",
    "\n",
    "# vector_index = SearchIndexModel(\n",
    "#     name=\"embedding_vector_index\",\n",
    "#     type=\"vectorSearch\",\n",
    "#     definition={\n",
    "#         \"fields\": [\n",
    "#             {\n",
    "#                 \"type\": \"vector\",\n",
    "#                 \"path\": \"embedding\",         # field that stores your embedding array\n",
    "#                 \"numDimensions\": DIMENSIONS,  # must match len(embedding)\n",
    "#                 \"similarity\": \"cosine\"       # or \"euclidean\" or \"dotProduct\"\n",
    "#             }\n",
    "#         ]\n",
    "#     },\n",
    "# )\n",
    "\n",
    "# # 3) Create the index\n",
    "# image_collection.create_search_index(model=vector_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0df44bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/17707 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17707/17707 [55:56<00:00,  5.27it/s]  \n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from pymongo import UpdateOne\n",
    "from pymongo.errors import BulkWriteError\n",
    "\n",
    "embedded_files = glob.glob(\n",
    "    \"../../../data/works_with_images_no_text_partitioned_embedded.parquet/*.parquet\")\n",
    "\n",
    "BATCH_SIZE = 1000          # tune for memory / speed\n",
    "PROGRESS_EVERY = 5000       # log every N attempted upserts\n",
    "\n",
    "\n",
    "def normalise_embedding(e):\n",
    "    \"\"\"Return list[float] (float32) or None.\n",
    "    Ensures the vector is JSON-serialisable and correct length.\n",
    "    \"\"\"\n",
    "    if e is None:\n",
    "        return None\n",
    "    if isinstance(e, (list, tuple)):\n",
    "        if len(e) != DIMENSIONS:\n",
    "            return None\n",
    "        return [float(x) for x in e]\n",
    "    try:\n",
    "        arr = np.asarray(e, dtype=np.float32)\n",
    "    except Exception:\n",
    "        return None\n",
    "    if arr.shape != (DIMENSIONS,):\n",
    "        return None\n",
    "    return arr.tolist()\n",
    "\n",
    "for file in tqdm.tqdm(embedded_files):\n",
    "    if processed_collection.find_one({\"file\": file}):\n",
    "        # Already successfully processed earlier\n",
    "        continue\n",
    "\n",
    "    # print(f\"Indexing {file}\")\n",
    "    df = pd.read_parquet(file)[[\"image_id\", \"embedding\"]]\n",
    "\n",
    "    # Drop null embeddings & duplicates within the file to reduce work\n",
    "    before = len(df)\n",
    "    df = df[df[\"embedding\"].notnull()].drop_duplicates(subset=[\"image_id\"]).copy()\n",
    "\n",
    "    # Normalise embeddings\n",
    "    df[\"embedding\"] = df[\"embedding\"].apply(normalise_embedding)\n",
    "    df = df[df[\"embedding\"].notnull()]\n",
    "    after = len(df)\n",
    "    # print(f\"Rows before: {before}, after filtering/normalising: {after}\")\n",
    "    if after == 0:\n",
    "        processed_collection.insert_one({\"file\": file})\n",
    "        continue\n",
    "\n",
    "    ops = []\n",
    "    attempted = 0\n",
    "    upserted_estimate = 0\n",
    "    duplicate_conflicts = 0\n",
    "\n",
    "    for rec in df.to_dict(orient=\"records\"):\n",
    "        ops.append(\n",
    "            UpdateOne(\n",
    "                {\"image_id\": rec[\"image_id\"]},\n",
    "                {\"$setOnInsert\": rec},\n",
    "                upsert=True,\n",
    "            )\n",
    "        )\n",
    "        if len(ops) >= BATCH_SIZE:\n",
    "            try:\n",
    "                result = image_collection.bulk_write(ops, ordered=False)\n",
    "                upserted_estimate += result.upserted_count\n",
    "            except BulkWriteError as bwe:\n",
    "                # Count duplicate key errors (code 11000); ignore them\n",
    "                write_errors = bwe.details.get(\"writeErrors\", [])\n",
    "                duplicate_conflicts += sum(1 for we in write_errors if we.get(\"code\") == 11000)\n",
    "                # Upserts that succeeded still count\n",
    "                upserted_estimate += bwe.details.get(\"nUpserted\", 0)\n",
    "            attempted += len(ops)\n",
    "            # if attempted % PROGRESS_EVERY == 0:\n",
    "                # print(\n",
    "                #     f\"Attempted {attempted} | inserted (new) ~{upserted_estimate} | duplicates ignored {duplicate_conflicts}\"\n",
    "                # )\n",
    "            ops = []\n",
    "\n",
    "    # Flush remaining\n",
    "    if ops:\n",
    "        try:\n",
    "            result = image_collection.bulk_write(ops, ordered=False)\n",
    "            upserted_estimate += result.upserted_count\n",
    "        except BulkWriteError as bwe:\n",
    "            write_errors = bwe.details.get(\"writeErrors\", [])\n",
    "            duplicate_conflicts += sum(1 for we in write_errors if we.get(\"code\") == 11000)\n",
    "            upserted_estimate += bwe.details.get(\"nUpserted\", 0)\n",
    "        attempted += len(ops)\n",
    "\n",
    "    # print(\n",
    "    #     f\"Finished {file}: attempted {attempted}, new inserted ~{upserted_estimate}, duplicates ignored {duplicate_conflicts}.\"\n",
    "    # )\n",
    "\n",
    "    processed_collection.insert_one({\"file\": file})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "19383f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_id': ObjectId('68da64cb9b5d3a5ad80a92c5'), 'image_id': 'https://iiif.wellcomecollection.org/image/b31650594_0160.jp2/full/718,1024/0/default.jpg', 'score': 0.5447544455528259}\n",
      "{'_id': ObjectId('68da63499b5d3a5ad8025e0d'), 'image_id': 'https://iiif.wellcomecollection.org/image/b2811680x_0369.jp2/full/587,1024/0/default.jpg', 'score': 0.5430546998977661}\n",
      "{'_id': ObjectId('68d5d2e54e032aa3a270d853'), 'image_id': 'https://iiif.wellcomecollection.org/image/b18024439_0877.JP2/full/718,1024/0/default.jpg', 'score': 0.542113721370697}\n",
      "{'_id': ObjectId('68da66e79b5d3a5ad814e0e7'), 'image_id': 'https://iiif.wellcomecollection.org/image/b31660575_0097.jp2/full/614,1024/0/default.jpg', 'score': 0.5397946834564209}\n",
      "{'_id': ObjectId('68da64679b5d3a5ad8088ed3'), 'image_id': 'https://iiif.wellcomecollection.org/image/b31809972_0008.jp2/full/660,1024/0/default.jpg', 'score': 0.538773775100708}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2. Your query embedding (length must match your index dimensions, e.g. 1536)\n",
    "# <-- replace with a real embedding from your model\n",
    "query_vector = [0.5] * 1536\n",
    "\n",
    "# 3. Run vector search aggregation\n",
    "pipeline = [\n",
    "    {\n",
    "        \"$vectorSearch\": {\n",
    "            \"index\": \"embedding_vector_index\",           # name of your search index\n",
    "            \"path\": \"embedding\",          # field where embeddings are stored\n",
    "            \"queryVector\": query_vector,  # your query vector\n",
    "            \"numCandidates\": 200,         # how many ANN candidates to consider\n",
    "            \"limit\": 5                    # top k results\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"$project\": {\n",
    "            \"image_id\": 1,\n",
    "            \"score\": {\"$meta\": \"vectorSearchScore\"}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "results = list(image_collection.aggregate(pipeline))\n",
    "\n",
    "for r in results:\n",
    "    print(r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagetalk-backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
